\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
\author{Daniel Deutsch and Daniel Crankshaw}
\title{Machine Learning Project}
\date{}
\begin{document}
\maketitle
\section*{Overview}
The idea for our project is to perform handwritten digit classification and compare the accuracies of several machine learning algorithms on the data. We will be getting the data from the machine learning competition website, www.kaggle.com. We intend to compare the performance of two machine learning algorithms, Neural Networks and K-Nearest Neighbors, on handwritten digit classification. We also intend to examine the effect of varying certain parameters of each algorithm. 

For Neural Networks, we will use both a two layer and a three layer network. For both networks, we will also look at the effects of varying the number of hidden nodes. If we have time, we would also like to implement a simple convolutional network to compare it with the neural networks. 

For nearest neighbors, we will look at using an epsilon ball approach and a standard k-nearest neighbors approach. In both cases, we will examine unweighted and weighted based on distance variants.

\section*{Resources}
The data for our project will be coming from the \href{http://yann.lecun.com/exdb/mnist/index.html}{MNIST database of handwritten digits}, which is a collection of handwritten digits, 0-9. We donâ€™t anticipate needing any other extra libraries to implement our algorithms.

\section*{Milestones}
Must achieve:
\begin{enumerate}
\item Implementation of a two layer neural network
\item Implementation of k nearest neighbors
\item Comparisons of prediction efficiency and accuracy between the two algorithms
\end{enumerate}
Expect to achieve
\begin{enumerate}
\item Efficiency and accuracy results as a function of the input parameters for each algorithm
\item Implementation of an epsilon ball nearest neighbors algorithm
\item Implementation of a three layer neural network
\end{enumerate}
Would like to achieve:
\begin{enumerate}
\item Convolutional neural network implementation
\end{enumerate}

\section*{Final Paper Outline}
\begin{enumerate}[I.]
\item Introduction
\item Methodology
\begin{enumerate}
\item description of algorithms and the motivation for why we selected these two algorithms to compare
\item description of parameters we are going to tune and how they change the algorithms
\end{enumerate}
\item Results of algorithms
\item Comparisons within each algorithm (meaning the variation of the parameters to decide which is the best as well as which version of the algorithms are best)
\item Comparisons between algorithms (neural networks vs. k-NN)
\item Conclusion and final recommendation
\end{enumerate}

\section*{Sources}
\begin{enumerate}
\item The MNIST database of handwritten digits: http://yann.lecun.com/exdb/mnist/index.html
\item The Kaggle competition website: http://www.kaggle.com/c/digit-recognizer 
\item The data:  http://www.kaggle.com/c/digit-recognizer/download/train.csv (train) and http://www.kaggle.com/c/digit-recognizer/download/test.csv (test)
\end{enumerate}

\end{document}